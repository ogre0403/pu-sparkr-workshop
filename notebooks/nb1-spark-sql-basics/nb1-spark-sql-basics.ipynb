{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkSQL basics with SparkR  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Introduction to Apache Spark with R by J. A. Dianes**](https://github.com/jadianes/spark-r-notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will introduce basic concepts about SparkSQL with R that you can find in the [SparkR documentation](http://spark.apache.org/docs/latest/sparkr.html), applied to the [2013 American Community Survey dataset](http://www.census.gov/programs-surveys/acs/data/summary-file.html). We will do two things, read data into a SparkSQL data frame, and have a quick look at the schema and what we have read. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a SparkSQL context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In further notebooks, we will explore our data by loading them into SparkSQL data frames. But first we need to init a SparkSQL context. The first thing we need to do is to set up some environment variables and library paths as follows. Remember to replace the value assigned to `SPARK_HOME` with your Spark home folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set Spark home and R libs\n",
    "# Sys.setenv(SPARK_HOME='/home/cluster/spark-1.5.0-bin-hadoop2.6')\n",
    "# .libPaths(c(file.path(Sys.getenv('SPARK_HOME'), 'R', 'lib'), .libPaths()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the `SparkR` library as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘SparkR’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    cov, filter, lag, na.omit, predict, sd, var, window\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.data.frame, colnames, colnames<-, drop, endsWith, intersect,\n",
      "    rank, rbind, sample, startsWith, subset, summary, transform, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(SparkR, lib.loc = c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\", \"lib\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can initialise the Spark context as [in the official documentation](http://spark.apache.org/docs/latest/sparkr.html#starting-up-sparkcontext-sqlcontext). In our case we are use a standalone Spark cluster with one master and seven workers. If you are running Spark in local node, use just `master='local'`. Additionally, we require a Spark package from Databricks to read CSV files (more on this in the next section).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spark package found in SPARK_HOME: /opt/spark\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching java with spark-submit command /opt/spark/bin/spark-submit  --packages com.databricks:spark-csv_2.11:1.2.0 --driver-memory \"2g\" sparkr-shell /tmp/RtmpqMAnJW/backend_port27014aef5147 \n"
     ]
    }
   ],
   "source": [
    "# sc <- sparkR.init(master='spark://169.254.206.2:7077', sparkPackages=\"com.databricks:spark-csv_2.11:1.2.0\")\n",
    "sqlContext <- sparkR.session(master = \"local[*]\", sparkConfig = list(spark.driver.memory = \"2g\") ,sparkPackages = \"com.databricks:spark-csv_2.11:1.2.0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can start the SparkSQL context as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sqlContext <- sparkRSQL.init(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SparkSQL data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading CSV data using Databricks csv extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The easiest way to get our CSV data into a [SparkSQL dataframe](http://spark.apache.org/docs/latest/sparkr.html#creating-dataframes), is by using [Databricks CSV extension](https://github.com/databricks/spark-csv) to read SparkSQL dataframes directly from csv files. In any case, remember to set the right path for your data files in the first line, ours is `/home/spark/pu_workshop/data/2013-acs/ss13husa.csv`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "housing_a_file_path <- file.path('', 'home','spark','pu_workshop','data','2013-acs','ss13husa.csv')\n",
    "housing_b_file_path <- file.path('', 'home','spark','pu_workshop','data','2013-acs','ss13husa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read into a SparkSQL dataframe. We need to pass four parameters in addition to the `sqlContext`:  \n",
    "\n",
    "- The file path.  \n",
    "- `header='true'` since our `csv` files have a header with the column names. \n",
    "- Indicate that we want the library to infer the schema.  \n",
    "- And the source type (the Databricks package in this case).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.004   0.000  19.726 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system.time(\n",
    "    housing_a_df <- read.df(\n",
    "        #sqlContext, \n",
    "                        housing_a_file_path, \n",
    "                        header='true', \n",
    "                        source = \"com.databricks.spark.csv\", \n",
    "                        inferSchema='true')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the inferred schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RT: string (nullable = true)\n",
      " |-- SERIALNO: integer (nullable = true)\n",
      " |-- DIVISION: integer (nullable = true)\n",
      " |-- PUMA: integer (nullable = true)\n",
      " |-- REGION: integer (nullable = true)\n",
      " |-- ST: integer (nullable = true)\n",
      " |-- ADJHSG: integer (nullable = true)\n",
      " |-- ADJINC: integer (nullable = true)\n",
      " |-- WGTP: integer (nullable = true)\n",
      " |-- NP: integer (nullable = true)\n",
      " |-- TYPE: integer (nullable = true)\n",
      " |-- ACCESS: integer (nullable = true)\n",
      " |-- ACR: integer (nullable = true)\n",
      " |-- AGS: integer (nullable = true)\n",
      " |-- BATH: integer (nullable = true)\n",
      " |-- BDSP: integer (nullable = true)\n",
      " |-- BLD: integer (nullable = true)\n",
      " |-- BROADBND: integer (nullable = true)\n",
      " |-- BUS: integer (nullable = true)\n",
      " |-- COMPOTHX: integer (nullable = true)\n",
      " |-- CONP: integer (nullable = true)\n",
      " |-- DIALUP: integer (nullable = true)\n",
      " |-- DSL: integer (nullable = true)\n",
      " |-- ELEP: integer (nullable = true)\n",
      " |-- FIBEROP: integer (nullable = true)\n",
      " |-- FS: integer (nullable = true)\n",
      " |-- FULP: integer (nullable = true)\n",
      " |-- GASP: integer (nullable = true)\n",
      " |-- HANDHELD: integer (nullable = true)\n",
      " |-- HFL: integer (nullable = true)\n",
      " |-- INSP: integer (nullable = true)\n",
      " |-- LAPTOP: integer (nullable = true)\n",
      " |-- MHP: integer (nullable = true)\n",
      " |-- MODEM: integer (nullable = true)\n",
      " |-- MRGI: integer (nullable = true)\n",
      " |-- MRGP: integer (nullable = true)\n",
      " |-- MRGT: integer (nullable = true)\n",
      " |-- MRGX: integer (nullable = true)\n",
      " |-- OTHSVCEX: integer (nullable = true)\n",
      " |-- REFR: integer (nullable = true)\n",
      " |-- RMSP: integer (nullable = true)\n",
      " |-- RNTM: integer (nullable = true)\n",
      " |-- RNTP: integer (nullable = true)\n",
      " |-- RWAT: integer (nullable = true)\n",
      " |-- RWATPR: integer (nullable = true)\n",
      " |-- SATELLITE: integer (nullable = true)\n",
      " |-- SINK: integer (nullable = true)\n",
      " |-- SMP: integer (nullable = true)\n",
      " |-- STOV: integer (nullable = true)\n",
      " |-- TEL: integer (nullable = true)\n",
      " |-- TEN: integer (nullable = true)\n",
      " |-- TOIL: integer (nullable = true)\n",
      " |-- VACS: integer (nullable = true)\n",
      " |-- VALP: integer (nullable = true)\n",
      " |-- VEH: integer (nullable = true)\n",
      " |-- WATP: integer (nullable = true)\n",
      " |-- YBL: integer (nullable = true)\n",
      " |-- FES: integer (nullable = true)\n",
      " |-- FFINCP: integer (nullable = true)\n",
      " |-- FGRNTP: integer (nullable = true)\n",
      " |-- FHINCP: integer (nullable = true)\n",
      " |-- FINCP: integer (nullable = true)\n",
      " |-- FPARC: integer (nullable = true)\n",
      " |-- FSMOCP: integer (nullable = true)\n",
      " |-- GRNTP: integer (nullable = true)\n",
      " |-- GRPIP: integer (nullable = true)\n",
      " |-- HHL: integer (nullable = true)\n",
      " |-- HHT: integer (nullable = true)\n",
      " |-- HINCP: integer (nullable = true)\n",
      " |-- HUGCL: integer (nullable = true)\n",
      " |-- HUPAC: integer (nullable = true)\n",
      " |-- HUPAOC: integer (nullable = true)\n",
      " |-- HUPARC: integer (nullable = true)\n",
      " |-- KIT: integer (nullable = true)\n",
      " |-- LNGI: integer (nullable = true)\n",
      " |-- MULTG: integer (nullable = true)\n",
      " |-- MV: integer (nullable = true)\n",
      " |-- NOC: integer (nullable = true)\n",
      " |-- NPF: integer (nullable = true)\n",
      " |-- NPP: integer (nullable = true)\n",
      " |-- NR: integer (nullable = true)\n",
      " |-- NRC: integer (nullable = true)\n",
      " |-- OCPIP: integer (nullable = true)\n",
      " |-- PARTNER: integer (nullable = true)\n",
      " |-- PLM: integer (nullable = true)\n",
      " |-- PSF: integer (nullable = true)\n",
      " |-- R18: integer (nullable = true)\n",
      " |-- R60: integer (nullable = true)\n",
      " |-- R65: integer (nullable = true)\n",
      " |-- RESMODE: integer (nullable = true)\n",
      " |-- SMOCP: integer (nullable = true)\n",
      " |-- SMX: integer (nullable = true)\n",
      " |-- SRNT: integer (nullable = true)\n",
      " |-- SSMC: integer (nullable = true)\n",
      " |-- SVAL: integer (nullable = true)\n",
      " |-- TAXP: integer (nullable = true)\n",
      " |-- WIF: integer (nullable = true)\n",
      " |-- WKEXREL: integer (nullable = true)\n",
      " |-- WORKSTAT: integer (nullable = true)\n",
      " |-- FACCESSP: integer (nullable = true)\n",
      " |-- FACRP: integer (nullable = true)\n",
      " |-- FAGSP: integer (nullable = true)\n",
      " |-- FBATHP: integer (nullable = true)\n",
      " |-- FBDSP: integer (nullable = true)\n",
      " |-- FBLDP: integer (nullable = true)\n",
      " |-- FBROADBNDP: integer (nullable = true)\n",
      " |-- FBUSP: integer (nullable = true)\n",
      " |-- FCOMPOTHXP: integer (nullable = true)\n",
      " |-- FCONP: integer (nullable = true)\n",
      " |-- FDIALUPP: integer (nullable = true)\n",
      " |-- FDSLP: integer (nullable = true)\n",
      " |-- FELEP: integer (nullable = true)\n",
      " |-- FFIBEROPP: integer (nullable = true)\n",
      " |-- FFSP: integer (nullable = true)\n",
      " |-- FFULP: integer (nullable = true)\n",
      " |-- FGASP: integer (nullable = true)\n",
      " |-- FHANDHELDP: integer (nullable = true)\n",
      " |-- FHFLP: integer (nullable = true)\n",
      " |-- FINSP: integer (nullable = true)\n",
      " |-- FKITP: integer (nullable = true)\n",
      " |-- FLAPTOPP: integer (nullable = true)\n",
      " |-- FMHP: integer (nullable = true)\n",
      " |-- FMODEMP: integer (nullable = true)\n",
      " |-- FMRGIP: integer (nullable = true)\n",
      " |-- FMRGP: integer (nullable = true)\n",
      " |-- FMRGTP: integer (nullable = true)\n",
      " |-- FMRGXP: integer (nullable = true)\n",
      " |-- FMVP: integer (nullable = true)\n",
      " |-- FOTHSVCEXP: integer (nullable = true)\n",
      " |-- FPLMP: integer (nullable = true)\n",
      " |-- FREFRP: integer (nullable = true)\n",
      " |-- FRMSP: integer (nullable = true)\n",
      " |-- FRNTMP: integer (nullable = true)\n",
      " |-- FRNTP: integer (nullable = true)\n",
      " |-- FRWATP: integer (nullable = true)\n",
      " |-- FRWATPRP: integer (nullable = true)\n",
      " |-- FSATELLITEP: integer (nullable = true)\n",
      " |-- FSINKP: integer (nullable = true)\n",
      " |-- FSMP: integer (nullable = true)\n",
      " |-- FSMXHP: integer (nullable = true)\n",
      " |-- FSMXSP: integer (nullable = true)\n",
      " |-- FSTOVP: integer (nullable = true)\n",
      " |-- FTAXP: integer (nullable = true)\n",
      " |-- FTELP: integer (nullable = true)\n",
      " |-- FTENP: integer (nullable = true)\n",
      " |-- FTOILP: integer (nullable = true)\n",
      " |-- FVACSP: integer (nullable = true)\n",
      " |-- FVALP: integer (nullable = true)\n",
      " |-- FVEHP: integer (nullable = true)\n",
      " |-- FWATP: integer (nullable = true)\n",
      " |-- FYBLP: integer (nullable = true)\n",
      " |-- wgtp1: integer (nullable = true)\n",
      " |-- wgtp2: integer (nullable = true)\n",
      " |-- wgtp3: integer (nullable = true)\n",
      " |-- wgtp4: integer (nullable = true)\n",
      " |-- wgtp5: integer (nullable = true)\n",
      " |-- wgtp6: integer (nullable = true)\n",
      " |-- wgtp7: integer (nullable = true)\n",
      " |-- wgtp8: integer (nullable = true)\n",
      " |-- wgtp9: integer (nullable = true)\n",
      " |-- wgtp10: integer (nullable = true)\n",
      " |-- wgtp11: integer (nullable = true)\n",
      " |-- wgtp12: integer (nullable = true)\n",
      " |-- wgtp13: integer (nullable = true)\n",
      " |-- wgtp14: integer (nullable = true)\n",
      " |-- wgtp15: integer (nullable = true)\n",
      " |-- wgtp16: integer (nullable = true)\n",
      " |-- wgtp17: integer (nullable = true)\n",
      " |-- wgtp18: integer (nullable = true)\n",
      " |-- wgtp19: integer (nullable = true)\n",
      " |-- wgtp20: integer (nullable = true)\n",
      " |-- wgtp21: integer (nullable = true)\n",
      " |-- wgtp22: integer (nullable = true)\n",
      " |-- wgtp23: integer (nullable = true)\n",
      " |-- wgtp24: integer (nullable = true)\n",
      " |-- wgtp25: integer (nullable = true)\n",
      " |-- wgtp26: integer (nullable = true)\n",
      " |-- wgtp27: integer (nullable = true)\n",
      " |-- wgtp28: integer (nullable = true)\n",
      " |-- wgtp29: integer (nullable = true)\n",
      " |-- wgtp30: integer (nullable = true)\n",
      " |-- wgtp31: integer (nullable = true)\n",
      " |-- wgtp32: integer (nullable = true)\n",
      " |-- wgtp33: integer (nullable = true)\n",
      " |-- wgtp34: integer (nullable = true)\n",
      " |-- wgtp35: integer (nullable = true)\n",
      " |-- wgtp36: integer (nullable = true)\n",
      " |-- wgtp37: integer (nullable = true)\n",
      " |-- wgtp38: integer (nullable = true)\n",
      " |-- wgtp39: integer (nullable = true)\n",
      " |-- wgtp40: integer (nullable = true)\n",
      " |-- wgtp41: integer (nullable = true)\n",
      " |-- wgtp42: integer (nullable = true)\n",
      " |-- wgtp43: integer (nullable = true)\n",
      " |-- wgtp44: integer (nullable = true)\n",
      " |-- wgtp45: integer (nullable = true)\n",
      " |-- wgtp46: integer (nullable = true)\n",
      " |-- wgtp47: integer (nullable = true)\n",
      " |-- wgtp48: integer (nullable = true)\n",
      " |-- wgtp49: integer (nullable = true)\n",
      " |-- wgtp50: integer (nullable = true)\n",
      " |-- wgtp51: integer (nullable = true)\n",
      " |-- wgtp52: integer (nullable = true)\n",
      " |-- wgtp53: integer (nullable = true)\n",
      " |-- wgtp54: integer (nullable = true)\n",
      " |-- wgtp55: integer (nullable = true)\n",
      " |-- wgtp56: integer (nullable = true)\n",
      " |-- wgtp57: integer (nullable = true)\n",
      " |-- wgtp58: integer (nullable = true)\n",
      " |-- wgtp59: integer (nullable = true)\n",
      " |-- wgtp60: integer (nullable = true)\n",
      " |-- wgtp61: integer (nullable = true)\n",
      " |-- wgtp62: integer (nullable = true)\n",
      " |-- wgtp63: integer (nullable = true)\n",
      " |-- wgtp64: integer (nullable = true)\n",
      " |-- wgtp65: integer (nullable = true)\n",
      " |-- wgtp66: integer (nullable = true)\n",
      " |-- wgtp67: integer (nullable = true)\n",
      " |-- wgtp68: integer (nullable = true)\n",
      " |-- wgtp69: integer (nullable = true)\n",
      " |-- wgtp70: integer (nullable = true)\n",
      " |-- wgtp71: integer (nullable = true)\n",
      " |-- wgtp72: integer (nullable = true)\n",
      " |-- wgtp73: integer (nullable = true)\n",
      " |-- wgtp74: integer (nullable = true)\n",
      " |-- wgtp75: integer (nullable = true)\n",
      " |-- wgtp76: integer (nullable = true)\n",
      " |-- wgtp77: integer (nullable = true)\n",
      " |-- wgtp78: integer (nullable = true)\n",
      " |-- wgtp79: integer (nullable = true)\n",
      " |-- wgtp80: integer (nullable = true)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.000   0.004   0.060 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system.time(\n",
    "    printSchema(housing_a_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Let's have a look at the first few rows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>RT</th><th scope=col>SERIALNO</th><th scope=col>DIVISION</th><th scope=col>PUMA</th><th scope=col>REGION</th><th scope=col>ST</th><th scope=col>ADJHSG</th><th scope=col>ADJINC</th><th scope=col>WGTP</th><th scope=col>NP</th><th scope=col>⋯</th><th scope=col>wgtp71</th><th scope=col>wgtp72</th><th scope=col>wgtp73</th><th scope=col>wgtp74</th><th scope=col>wgtp75</th><th scope=col>wgtp76</th><th scope=col>wgtp77</th><th scope=col>wgtp78</th><th scope=col>wgtp79</th><th scope=col>wgtp80</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>H      </td><td> 84    </td><td>6      </td><td>2600   </td><td>3      </td><td>1      </td><td>1000000</td><td>1007549</td><td>  0    </td><td>1      </td><td>⋯      </td><td>  0    </td><td>  0    </td><td>  0    </td><td>  0    </td><td>  0    </td><td>  0    </td><td>  0    </td><td>  0    </td><td>  0    </td><td>  0    </td></tr>\n",
       "\t<tr><td>H      </td><td>154    </td><td>6      </td><td>2500   </td><td>3      </td><td>1      </td><td>1000000</td><td>1007549</td><td> 51    </td><td>4      </td><td>⋯      </td><td> 86    </td><td> 53    </td><td> 59    </td><td> 84    </td><td> 49    </td><td> 15    </td><td> 15    </td><td> 20    </td><td> 50    </td><td> 16    </td></tr>\n",
       "\t<tr><td>H      </td><td>156    </td><td>6      </td><td>1700   </td><td>3      </td><td>1      </td><td>1000000</td><td>1007549</td><td>449    </td><td>1      </td><td>⋯      </td><td>161    </td><td>530    </td><td>601    </td><td>579    </td><td>341    </td><td>378    </td><td>387    </td><td>421    </td><td>621    </td><td>486    </td></tr>\n",
       "\t<tr><td>H      </td><td>160    </td><td>6      </td><td>2200   </td><td>3      </td><td>1      </td><td>1000000</td><td>1007549</td><td> 16    </td><td>3      </td><td>⋯      </td><td> 31    </td><td> 24    </td><td> 33    </td><td>  7    </td><td>  7    </td><td> 13    </td><td> 18    </td><td> 23    </td><td> 23    </td><td>  5    </td></tr>\n",
       "\t<tr><td>H      </td><td>231    </td><td>6      </td><td>2400   </td><td>3      </td><td>1      </td><td>1000000</td><td>1007549</td><td> 52    </td><td>1      </td><td>⋯      </td><td> 21    </td><td> 18    </td><td> 37    </td><td> 49    </td><td>103    </td><td> 38    </td><td> 49    </td><td> 51    </td><td> 46    </td><td> 47    </td></tr>\n",
       "\t<tr><td>H      </td><td>286    </td><td>6      </td><td> 900   </td><td>3      </td><td>1      </td><td>1000000</td><td>1007549</td><td> 76    </td><td>1      </td><td>⋯      </td><td>128    </td><td> 25    </td><td> 68    </td><td> 66    </td><td> 80    </td><td> 26    </td><td> 66    </td><td>164    </td><td> 88    </td><td> 24    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " RT & SERIALNO & DIVISION & PUMA & REGION & ST & ADJHSG & ADJINC & WGTP & NP & ⋯ & wgtp71 & wgtp72 & wgtp73 & wgtp74 & wgtp75 & wgtp76 & wgtp77 & wgtp78 & wgtp79 & wgtp80\\\\\n",
       "\\hline\n",
       "\t H       &  84     & 6       & 2600    & 3       & 1       & 1000000 & 1007549 &   0     & 1       & ⋯       &   0     &   0     &   0     &   0     &   0     &   0     &   0     &   0     &   0     &   0    \\\\\n",
       "\t H       & 154     & 6       & 2500    & 3       & 1       & 1000000 & 1007549 &  51     & 4       & ⋯       &  86     &  53     &  59     &  84     &  49     &  15     &  15     &  20     &  50     &  16    \\\\\n",
       "\t H       & 156     & 6       & 1700    & 3       & 1       & 1000000 & 1007549 & 449     & 1       & ⋯       & 161     & 530     & 601     & 579     & 341     & 378     & 387     & 421     & 621     & 486    \\\\\n",
       "\t H       & 160     & 6       & 2200    & 3       & 1       & 1000000 & 1007549 &  16     & 3       & ⋯       &  31     &  24     &  33     &   7     &   7     &  13     &  18     &  23     &  23     &   5    \\\\\n",
       "\t H       & 231     & 6       & 2400    & 3       & 1       & 1000000 & 1007549 &  52     & 1       & ⋯       &  21     &  18     &  37     &  49     & 103     &  38     &  49     &  51     &  46     &  47    \\\\\n",
       "\t H       & 286     & 6       &  900    & 3       & 1       & 1000000 & 1007549 &  76     & 1       & ⋯       & 128     &  25     &  68     &  66     &  80     &  26     &  66     & 164     &  88     &  24    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "RT | SERIALNO | DIVISION | PUMA | REGION | ST | ADJHSG | ADJINC | WGTP | NP | ⋯ | wgtp71 | wgtp72 | wgtp73 | wgtp74 | wgtp75 | wgtp76 | wgtp77 | wgtp78 | wgtp79 | wgtp80 | \n",
       "|---|---|---|---|---|---|\n",
       "| H       |  84     | 6       | 2600    | 3       | 1       | 1000000 | 1007549 |   0     | 1       | ⋯       |   0     |   0     |   0     |   0     |   0     |   0     |   0     |   0     |   0     |   0     | \n",
       "| H       | 154     | 6       | 2500    | 3       | 1       | 1000000 | 1007549 |  51     | 4       | ⋯       |  86     |  53     |  59     |  84     |  49     |  15     |  15     |  20     |  50     |  16     | \n",
       "| H       | 156     | 6       | 1700    | 3       | 1       | 1000000 | 1007549 | 449     | 1       | ⋯       | 161     | 530     | 601     | 579     | 341     | 378     | 387     | 421     | 621     | 486     | \n",
       "| H       | 160     | 6       | 2200    | 3       | 1       | 1000000 | 1007549 |  16     | 3       | ⋯       |  31     |  24     |  33     |   7     |   7     |  13     |  18     |  23     |  23     |   5     | \n",
       "| H       | 231     | 6       | 2400    | 3       | 1       | 1000000 | 1007549 |  52     | 1       | ⋯       |  21     |  18     |  37     |  49     | 103     |  38     |  49     |  51     |  46     |  47     | \n",
       "| H       | 286     | 6       |  900    | 3       | 1       | 1000000 | 1007549 |  76     | 1       | ⋯       | 128     |  25     |  68     |  66     |  80     |  26     |  66     | 164     |  88     |  24     | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  RT SERIALNO DIVISION PUMA REGION ST ADJHSG  ADJINC  WGTP NP ⋯ wgtp71 wgtp72\n",
       "1 H   84      6        2600 3      1  1000000 1007549   0  1  ⋯   0      0   \n",
       "2 H  154      6        2500 3      1  1000000 1007549  51  4  ⋯  86     53   \n",
       "3 H  156      6        1700 3      1  1000000 1007549 449  1  ⋯ 161    530   \n",
       "4 H  160      6        2200 3      1  1000000 1007549  16  3  ⋯  31     24   \n",
       "5 H  231      6        2400 3      1  1000000 1007549  52  1  ⋯  21     18   \n",
       "6 H  286      6         900 3      1  1000000 1007549  76  1  ⋯ 128     25   \n",
       "  wgtp73 wgtp74 wgtp75 wgtp76 wgtp77 wgtp78 wgtp79 wgtp80\n",
       "1   0      0      0      0      0      0      0      0   \n",
       "2  59     84     49     15     15     20     50     16   \n",
       "3 601    579    341    378    387    421    621    486   \n",
       "4  33      7      7     13     18     23     23      5   \n",
       "5  37     49    103     38     49     51     46     47   \n",
       "6  68     66     80     26     66    164     88     24   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(housing_a_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's count how many rows do we have in the first dataset. For that we will use `nrow` as we do with regular R data frames. Let's have a look at the documentation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?nrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is just a definition of `nrow` by the package *SparkR*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "756065"
      ],
      "text/latex": [
       "756065"
      ],
      "text/markdown": [
       "756065"
      ],
      "text/plain": [
       "[1] 756065"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(housing_a_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the second housing data frame and count the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.021   0.094  15.259 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system.time(\n",
    "    housing_b_df <- read.df(\n",
    "        #sqlContext, \n",
    "                        housing_b_file_path, \n",
    "                        header='true', \n",
    "                        source = \"com.databricks.spark.csv\", \n",
    "                        inferSchema='true')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 756065\n"
     ]
    }
   ],
   "source": [
    "print(nrow(housing_b_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `rbind()` as we do with regular R data frames to put both of them together. Let's have a look at the documentation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?rbind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, SparkR redefines many of the common R functions to work with SparkSQL data frames. Let's actually use `rbind` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "housing_df <- rbind(housing_a_df, housing_b_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's count how many rows do we have in the complete data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.001   0.000  10.245 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1512130\n"
     ]
    }
   ],
   "source": [
    "system.time(\n",
    "    housing_samples <- nrow(housing_df)\n",
    ")\n",
    "print(housing_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's get a feeling of what is to explore data using SparkR by using the `summary` function on the data frame. Let's first have a look at the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "? summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we are redirected to `describe`, that optionally accepts column names. Let's use it with the whole data frame, that is, the 231 columns and 1476313 rows. *Note*: We use `collect` here because the results of `describe` are given as a `DataFrame` object and we need to print them in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "system.time(\n",
    "    housing_summary <- describe(housing_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collect(housing_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can select individual column summaries using `select` as follows (here is [a dictionary](http://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/PUMSDataDict13.txt) of each column meaning) where `VALP` is the property value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>VALP</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>859691</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>247682.84302150423</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>NaN</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>100</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>4775000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "  & VALP\\\\\n",
       "\\hline\n",
       "\t1 & 859691\\\\\n",
       "\t2 & 247682.84302150423\\\\\n",
       "\t3 & NaN\\\\\n",
       "\t4 & 100\\\\\n",
       "\t5 & 4775000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "                VALP\n",
       "1             859691\n",
       "2 247682.84302150423\n",
       "3                NaN\n",
       "4                100\n",
       "5            4775000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(select(housing_summary,\"VALP\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. In this notebook we have shown how to load a CSV file into an SparkSQL data frame using SparkR. We also had a look at the data loaded, mainly to the number of samples loaded, and the data summary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
